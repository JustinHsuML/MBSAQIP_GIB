{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from tensorflow import keras\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "pd.options.display.max_rows = 20\n",
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_ci(y_true, y_score, positive=1):\n",
    "    AUC = roc_auc_score(y_true, y_score)\n",
    "    N1 = sum(y_true == positive)\n",
    "    N2 = sum(y_true != positive)\n",
    "    Q1 = AUC / (2 - AUC)\n",
    "    Q2 = 2*AUC**2 / (1 + AUC)\n",
    "    SE_AUC = sqrt((AUC*(1 - AUC) + (N1 - 1)*(Q1 - AUC**2) + (N2 - 1)*(Q2 - AUC**2)) / (N1*N2))\n",
    "    lower = AUC - 1.96*SE_AUC\n",
    "    upper = AUC + 1.96*SE_AUC\n",
    "    if lower < 0:\n",
    "        lower = 0\n",
    "    if upper > 1:\n",
    "        upper = 1\n",
    "    return (lower, AUC, upper)\n",
    "\n",
    "def roc_prc_ci(y_true, y_score, positive=1):\n",
    "    AUC = average_precision_score(y_true, y_score)\n",
    "    N1 = sum(y_true == positive)\n",
    "    N2 = sum(y_true != positive)\n",
    "    Q1 = AUC / (2 - AUC)\n",
    "    Q2 = 2*AUC**2 / (1 + AUC)\n",
    "    SE_AUC = sqrt((AUC*(1 - AUC) + (N1 - 1)*(Q1 - AUC**2) + (N2 - 1)*(Q2 - AUC**2)) / (N1*N2))\n",
    "    lower = AUC - 1.96*SE_AUC\n",
    "    upper = AUC + 1.96*SE_AUC\n",
    "    if lower < 0:\n",
    "        lower = 0\n",
    "    if upper > 1:\n",
    "        upper = 1\n",
    "    return (lower, AUC, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_cptdc_nopost_noint_80.csv')\n",
    "test = pd.read_csv('test_cptdc_nopost_noint_20.csv')\n",
    "\n",
    "# /home/loganlog/Documents/mbsaqip_bleed/data/train_cptdc_nopost_noint.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape[0] / train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train, test], axis=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv('../data/lucky_13.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('/home/loganlog/Documents/mbsaqip_bleed/data/lucky_13.csv', index_col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# drop = ['GITRACTBLEED']\n",
    "# y = train['GITRACTBLEED']\n",
    "# X = train.drop(drop, axis=1)\n",
    "# y_test = test['GITRACTBLEED']\n",
    "# X_test = test.drop(drop, axis=1)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['GITRACTBLEED']\n",
    "y = data['GITRACTBLEED']\n",
    "X = data.drop(drop, axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape[0] / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "rf = RandomForestClassifier(n_estimators=1500, max_depth=20, max_features='sqrt', min_samples_leaf=8, min_samples_split=3, bootstrap=True, n_jobs=-1, random_state=0)\n",
    "xgb = XGBClassifier(n_estimators=100, max_depth=20, colsample_bytree=0.8, learning_rate=0.05, min_child_weight=4, subsample=1, random_state=0)\n",
    "# xgb = XGBClassifier(n_estimators=100, max_depth=20, colsample_bytree=0.8, learning_rate=0.05, min_child_weight=4, subsample=1, tree_method='gpu_hist', random_state=0)\n",
    "lr = LogisticRegression(penalty='none', random_state=0, max_iter=9999)\n",
    "\n",
    "input_shape = X.shape[1:]\n",
    "def build_model(n_hidden=3, n_neurons=1500, dropout=0.6, learning_rate=0.00003):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "        model.add(keras.layers.Activation(\"relu\"))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(), metrics=['AUC'], optimizer=optimizer)\n",
    "    return model\n",
    "nn = build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#calculate 95% confidence interval for auroc and auprc for each model (def = define function)\n",
    "def auroc_ci(y_true, y_pred):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    mean = roc_auc\n",
    "    std = sqrt(roc_auc * (1.0 - roc_auc) / len(y_true))\n",
    "    low  = mean - std\n",
    "    high = mean + std\n",
    "    return low, mean, high\n",
    "#calculate auprc 95% ci for each model\n",
    "def auprc_ci(y_true, y_pred):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    mean = pr_auc\n",
    "    std = sqrt(pr_auc * (1.0 - pr_auc) / len(y_true))\n",
    "    low  = mean - std\n",
    "    high = mean + std\n",
    "    return low, mean, high\n",
    "def fit_predict(model, X_train, y_train, X_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    return y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# New\n",
    "# cross_val_score(rf, X, y, scoring='roc_auc', cv=5)\n",
    "\n",
    "# scores = cross_val_score(xgb, X, y, scoring='roc_auc', cv=5)\n",
    "# import numpy as np\n",
    "# np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# rf_y_pred = fit_predict(rf, X, y, X_test)\n",
    "# xgb_y_pred = fit_predict(xgb, X, y, X_test)\n",
    "# lr_y_pred = fit_predict(lr, X, y, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "rf_y_pred = fit_predict(rf, X_train, y_train, X_test)\n",
    "xgb_y_pred = fit_predict(xgb, X_train, y_train, X_test)\n",
    "lr_y_pred = fit_predict(lr, X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "history = nn.fit(X_train, y_train,\n",
    "                batch_size=512, epochs=500,\n",
    "                validation_data=(X_test, y_test),\n",
    "                callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# New\n",
    "\n",
    "auroc_ci(y_test, xgb_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# New\n",
    "\n",
    "auroc_ci(y_test, rf_y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# New\n",
    "\n",
    "auroc_ci(y_test, lr_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# New\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# New\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install delong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# # New\n",
    "\n",
    "# p_val = delong.delong_roc_test(y_test, lr_y_pred, xgb_y_pred)\n",
    "# p_val2 = delong.delong_roc_test(y_test, lr_y_pred, rf_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# # New\n",
    "\n",
    "# 10 ** (p_val[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# # New\n",
    "\n",
    "# 10 ** (p_val2[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = xgb.feature_importances_.argsort()\n",
    "plt.barh(X.columns[sorted_idx], xgb.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"XGBoost Feature Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "nn_y_pred = nn.predict(X_test)\n",
    "rf_confidence = auroc_ci(y_test, rf_y_pred)\n",
    "xgb_confidence = auroc_ci(y_test, xgb_y_pred)\n",
    "lr_confidence = auroc_ci(y_test, lr_y_pred)\n",
    "nn_confidence = auroc_ci(y_test, nn_y_pred)\n",
    "print('Random Forest AUROC:', rf_confidence, 'AUROC CI:', rf_confidence)\n",
    "print('XGBoost AUROC:', xgb_confidence, 'AUROC CI:', xgb_confidence)\n",
    "print('Logistic Regression AUROC:', lr_confidence, 'AUROC CI:', lr_confidence)\n",
    "print('Neural Network AUROC:', nn_confidence, 'AUROC CI:', nn_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#create labels for roc curves\n",
    "rf_label = 'RF: ' + str(round(rf_confidence[1], 3)) + ' (' + str(round(rf_confidence[0], 3)) + ' - ' + str(round(rf_confidence[2], 3)) + ')'\n",
    "xgb_label = 'XGB: ' + str(round(xgb_confidence[1], 3)) + ' (' + str(round(xgb_confidence[0], 3)) + ' - ' + str(round(xgb_confidence[2], 3)) + ')'\n",
    "nn_label = 'NN: ' + str(round(nn_confidence[1], 3)) + ' (' + str(round(nn_confidence[0], 3)) + ' - ' + str(round(nn_confidence[2], 3)) + ')'\n",
    "lr_label = 'LR: ' + str(round(lr_confidence[1], 3)) + ' (' + str(round(lr_confidence[0], 3)) + ' - ' + str(round(lr_confidence[2], 3)) + ')'\n",
    "#calculate tpr and fpr for each model\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_y_pred)\n",
    "xgb_fpr, xgb_tpr, _ = roc_curve(y_test, xgb_y_pred)\n",
    "nn_fpr, nn_tpr, _ = roc_curve(y_test, nn_y_pred)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "#plot the ROC curves for each model\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(lr_fpr, lr_tpr, color='red', label=lr_label)\n",
    "plt.plot(rf_fpr, rf_tpr, color='deepskyblue', label=rf_label)\n",
    "plt.plot(xgb_fpr, xgb_tpr, color='steelblue', label=xgb_label)\n",
    "plt.plot(nn_fpr, nn_tpr, color='dodgerblue', label=nn_label)\n",
    "plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.savefig('roc_bleed_cptdc_nopost_noint_ab.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "rf_auprc_ci = auprc_ci(y_test, rf_y_pred)\n",
    "xgb_auprc_ci = auprc_ci(y_test, xgb_y_pred)\n",
    "lr_auprc_ci = auprc_ci(y_test, lr_y_pred)\n",
    "nn_auprc_ci = auprc_ci(y_test, nn_y_pred)\n",
    "#calculate precision and recall for each model\n",
    "rf_precision, rf_recall, _ = precision_recall_curve(y_test, rf_y_pred)\n",
    "xgb_precision, xgb_recall, _ = precision_recall_curve(y_test, xgb_y_pred)\n",
    "nn_precision, nn_recall, _ = precision_recall_curve(y_test, nn_y_pred)\n",
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_y_pred)\n",
    "#create labels for precision recall curves\n",
    "rf_prc_label = 'RF: ' + str(round(rf_auprc_ci[1], 3)) + ' (' + str(round(rf_auprc_ci[0], 3)) + ' - ' + str(round(rf_auprc_ci[2], 3)) + ')'\n",
    "xgb_prc_label = 'XGB: ' + str(round(xgb_auprc_ci[1], 3)) + ' (' + str(round(xgb_auprc_ci[0], 3)) + ' - ' + str(round(xgb_auprc_ci[2], 3)) + ')'\n",
    "nn_prc_label = 'NN: ' + str(round(nn_auprc_ci[1], 3)) + ' (' + str(round(nn_auprc_ci[0], 3)) + ' - ' + str(round(nn_auprc_ci[2], 3)) + ')'\n",
    "lr_prc_label = 'LR: ' + str(round(lr_auprc_ci[1], 3)) + ' (' + str(round(lr_auprc_ci[0], 3)) + ' - ' + str(round(lr_auprc_ci[2], 3)) + ')'\n",
    "#plot the precision recall curves for each model\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "#plot the ROC curves for each model\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(lr_recall, lr_precision, color='red', label=lr_prc_label)\n",
    "plt.plot(rf_recall, rf_precision, color='deepskyblue', label=rf_prc_label)\n",
    "plt.plot(xgb_recall, xgb_precision, color='steelblue', label=xgb_prc_label)\n",
    "plt.plot(nn_recall, nn_precision, color='dodgerblue', label=nn_prc_label)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.savefig('prc_bleed_cptdc_nopost_noint_ab.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "xgb.fit(X, y)\n",
    "fi = xgb.feature_importances_\n",
    "fi_sorted = np.argsort(fi)\n",
    "fi_sorted = fi_sorted[::-1]\n",
    "fi_sorted = fi_sorted[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#plot the top 15 feature on a horizontal bar chart, with highest on the top\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(np.arange(15), fi[fi_sorted], color='steelblue')\n",
    "plt.yticks(np.arange(15), X.columns[fi_sorted])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.savefig('xgb_fi_bleed_cptdc_nopost_noint_ab.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X, y)\n",
    "fi = rf.feature_importances_\n",
    "fi_sorted = np.argsort(fi)\n",
    "fi_sorted = fi_sorted[::-1]\n",
    "fi_sorted = fi_sorted[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#plot the top 15 feature on a horizontal bar chart, with highest on the top\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(np.arange(15), fi[fi_sorted], color='steelblue')\n",
    "plt.yticks(np.arange(15), X.columns[fi_sorted])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.savefig('rf_fi_bleed_cptdc_nopost_noint_ab.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.metrics import specificity_score\n",
    "import numpy as np\n",
    "thresh = np.arange(0, 1, 0.00001)\n",
    "#create a dataframe to store the sensitivity and specificity at each threshold for each model\n",
    "lr_senspec = pd.DataFrame(columns=['thresh', 'sens','spec'])\n",
    "xgb_senspec = pd.DataFrame(columns=['thresh', 'sens','spec'])\n",
    "rf_senspec = pd.DataFrame(columns=['thresh', 'sens','spec'])\n",
    "lr_sens = {}\n",
    "lr_spec = {}\n",
    "xgb_sens = {}\n",
    "xgb_spec = {}\n",
    "rf_sens = {}\n",
    "rf_spec = {}\n",
    "for t in thresh:\n",
    "    lr_sens[t] = recall_score(y_test, lr_y_pred > t)\n",
    "    lr_spec[t] = specificity_score(y_test, lr_y_pred > t)\n",
    "    xgb_sens[t] = recall_score(y_test, xgb_y_pred > t)\n",
    "    xgb_spec[t] = specificity_score(y_test, xgb_y_pred > t)\n",
    "    rf_sens[t] = recall_score(y_test, rf_y_pred > t)\n",
    "    rf_spec[t] = specificity_score(y_test, rf_y_pred > t)\n",
    "#add each dictionary to the dataframe\n",
    "lr_senspec['thresh'] = lr_sens.keys()\n",
    "lr_senspec['sens'] = lr_sens.values()\n",
    "lr_senspec['spec'] = lr_spec.values()\n",
    "xgb_senspec['thresh'] = xgb_sens.keys()\n",
    "xgb_senspec['sens'] = xgb_sens.values()\n",
    "xgb_senspec['spec'] = xgb_spec.values()\n",
    "rf_senspec['thresh'] = rf_sens.keys()\n",
    "rf_senspec['sens'] = rf_sens.values()\n",
    "rf_senspec['spec'] = rf_spec.values()\n",
    "#plot the sensitivity and specificity\n",
    "plt.plot(lr_senspec['thresh'], lr_senspec['sens'], label='LR')\n",
    "plt.plot(xgb_senspec['thresh'], xgb_senspec['sens'], label='xgb')\n",
    "plt.plot(rf_senspec['thresh'], rf_senspec['sens'], label='rf')\n",
    "plt.plot(lr_senspec['thresh'], lr_senspec['spec'], label='LR')\n",
    "plt.plot(xgb_senspec['thresh'], xgb_senspec['spec'], label='xgb')\n",
    "plt.plot(rf_senspec['thresh'], rf_senspec['spec'], label='rf')\n",
    "plt.legend()\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Sensitivity/Specificity')\n",
    "plt.title('Sensitivity/Specificity vs Threshold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "xgb_senatspec = {}\n",
    "rf_senatspec = {}\n",
    "lr_senatspec = {}\n",
    "#find the value for xgb sensitivity where specificity is close to 90%\n",
    "xgb_senatspec[90] = float(str(xgb_senspec['sens'].loc[round(xgb_senspec['spec'],1) == 0.900]).split()[1])\n",
    "rf_senatspec[90] = float(str(rf_senspec['sens'].loc[round(rf_senspec['spec'],1) == 0.900]).split()[1])\n",
    "lr_senatspec[90] = float(str(lr_senspec['sens'].loc[round(lr_senspec['spec'],1) == 0.900]).split()[1])\n",
    "\n",
    "xgb_senatspec[70] = float(str(xgb_senspec['sens'].loc[round(xgb_senspec['spec'],1) == 0.700]).split()[1])\n",
    "rf_senatspec[70] = float(str(rf_senspec['sens'].loc[round(rf_senspec['spec'],1) == 0.700]).split()[1])\n",
    "lr_senatspec[70] = float(str(lr_senspec['sens'].loc[round(lr_senspec['spec'],1) == 0.700]).split()[1])\n",
    "\n",
    "xgb_senatspec[50] = float(str(xgb_senspec['sens'].loc[round(xgb_senspec['spec'],1) == 0.500]).split()[1])\n",
    "rf_senatspec[50] = float(str(rf_senspec['sens'].loc[round(rf_senspec['spec'],1) == 0.500]).split()[1])\n",
    "lr_senatspec[50] = float(str(lr_senspec['sens'].loc[round(lr_senspec['spec'],1) == 0.500]).split()[1])\n",
    "\n",
    "xgb_senatspec[30] = float(str(xgb_senspec['sens'].loc[round(xgb_senspec['spec'],1) == 0.300]).split()[1])\n",
    "rf_senatspec[30] = float(str(rf_senspec['sens'].loc[round(rf_senspec['spec'],1) == 0.300]).split()[1])\n",
    "lr_senatspec[30] = float(str(lr_senspec['sens'].loc[round(lr_senspec['spec'],1) == 0.300]).split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "xgb_senatspec[10] = float(str(xgb_senspec['sens'].loc[round(xgb_senspec['spec'],1) == 0.100]).split()[1])\n",
    "rf_senatspec[10] = float(str(rf_senspec['sens'].loc[round(rf_senspec['spec'],1) == 0.100]).split()[1])\n",
    "lr_senatspec[10] = float(str(lr_senspec['sens'].loc[round(lr_senspec['spec'],1) == 0.100]).split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "xgb_senspec['spec'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#write xgb_senatspec to a csv file\n",
    "xgb_senatspec_df = pd.DataFrame.from_dict(xgb_senatspec, orient='index')\n",
    "xgb_senatspec_df.columns = ['sensitivity']\n",
    "#rename index to 'specificity'\n",
    "xgb_senatspec_df.index.name = 'specificity'\n",
    "xgb_senatspec_df.to_csv('xgb_senspec_bleed_cptdc_nopost_noint_ab.csv')\n",
    "\n",
    "rf_senatspec_df = pd.DataFrame.from_dict(rf_senatspec, orient='index')\n",
    "rf_senatspec_df.columns = ['sensitivity']\n",
    "#rename index to 'specificity'\n",
    "rf_senatspec_df.index.name = 'specificity'\n",
    "rf_senatspec_df.to_csv('rf_senspec_bleed_cptdc_nopost_noint_ab.csv')\n",
    "\n",
    "lr_senatspec_df = pd.DataFrame.from_dict(lr_senatspec, orient='index')\n",
    "lr_senatspec_df.columns = ['sensitivity']\n",
    "#rename index to 'specificity'\n",
    "lr_senatspec_df.index.name = 'specificity'\n",
    "lr_senatspec_df.to_csv('lr_senspec_bleed_cptdc_nopost_noint_ab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
